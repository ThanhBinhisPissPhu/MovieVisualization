{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_json('separated_movies/movies.jsonl', lines=True)\n",
    "actors = pd.read_json('separated_movies/actors.jsonl', lines=True)\n",
    "directors = pd.read_json('separated_movies/directors.jsonl', lines=True)\n",
    "genres = pd.read_json('separated_movies/genres.jsonl', lines=True)\n",
    "movies_actors = pd.read_json('separated_movies/movies_actors.jsonl', lines=True)\n",
    "movies_directors = pd.read_json('separated_movies/movies_directors.jsonl', lines=True)\n",
    "movies_genres = pd.read_json('separated_movies/movies_genres.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.05\n",
    "sample_size = 10\n",
    "# streaming_movies = movies.sample(frac=split_ratio, random_state=42)\n",
    "streaming_movies = movies.sample(n=sample_size, random_state=42)\n",
    "\n",
    "db_movies = movies.drop(streaming_movies.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84661, 10, 84651)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies), len(streaming_movies), len(db_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_movie_ids = streaming_movies['item_id'].unique()\n",
    "len(streaming_movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_movies_actors = movies_actors[~movies_actors['item_id'].isin(streaming_movie_ids)]\n",
    "db_movies_directors = movies_directors[~movies_directors['item_id'].isin(streaming_movie_ids)]\n",
    "db_movies_genres = movies_genres[~movies_genres['item_id'].isin(streaming_movie_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_movies = pd.read_json('separated_movies/raw_movies.jsonl', lines=True)\n",
    "streaming_movies['positive_reviews'] = 0\n",
    "streaming_movies['negative_reviews'] = 0\n",
    "streaming_movies['neutral_reviews'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_movies = streaming_movies[streaming_movies['item_id'].isin(streaming_movie_ids)]\n",
    "streaming_movies.to_json('dags/streaming_data/streaming_movies.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_movies.to_json('db_data/db_movies.jsonl', orient='records', lines=True)\n",
    "db_movies_actors.to_json('db_data/db_movies_actors.jsonl', orient='records', lines=True)\n",
    "db_movies_directors.to_json('db_data/db_movies_directors.jsonl', orient='records', lines=True)\n",
    "db_movies_genres.to_json('db_data/db_movies_genres.jsonl', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100000  # Number of records per chunk\n",
    "\n",
    "input_file = 'separated_movies/ratings.jsonl'\n",
    "output_db_file = 'db_data/db_ratings.jsonl'\n",
    "output_streaming_file = 'dags/streaming_data/streaming_ratings.jsonl'\n",
    "\n",
    "# Initialize flags for first write\n",
    "first_write = True\n",
    "\n",
    "# Process file in chunks\n",
    "for chunk in pd.read_json(input_file, lines=True, chunksize=chunk_size):\n",
    "    # Filter for DB and streaming\n",
    "    filtered_chunk = chunk[~chunk['item_id'].isin(streaming_movie_ids)]\n",
    "    streaming_chunk = chunk[chunk['item_id'].isin(streaming_movie_ids)]\n",
    "    \n",
    "    # Determine write mode based on first_write flag\n",
    "    db_mode = 'w' if first_write else 'a'\n",
    "    streaming_mode = 'w' if first_write else 'a'\n",
    "    \n",
    "    # Write to the DB file\n",
    "    with open(output_db_file, db_mode) as db_file:\n",
    "        filtered_chunk.to_json(db_file, orient='records', lines=True)\n",
    "    \n",
    "    # Write to the streaming file\n",
    "    with open(output_streaming_file, streaming_mode) as streaming_file:\n",
    "        streaming_chunk.to_json(streaming_file, orient='records', lines=True)\n",
    "    \n",
    "    # After first write, switch to append mode\n",
    "    first_write = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 100000  # Number of records per chunk\n",
    "\n",
    "input_file = 'separated_movies/reviews.jsonl'\n",
    "output_db_file = 'db_data/db_reviews.jsonl'\n",
    "output_streaming_file = 'dags/streaming_data/streaming_reviews.jsonl'\n",
    "\n",
    "# Initialize flags for first write\n",
    "first_write = True\n",
    "\n",
    "# Process file in chunks\n",
    "for chunk in pd.read_json(input_file, lines=True, chunksize=chunk_size):\n",
    "    # Filter for DB and streaming\n",
    "    filtered_chunk = chunk[~chunk['item_id'].isin(streaming_movie_ids)]\n",
    "    streaming_chunk = chunk[chunk['item_id'].isin(streaming_movie_ids)]\n",
    "    \n",
    "    # Determine write mode based on first_write flag\n",
    "    db_mode = 'w' if first_write else 'a'\n",
    "    streaming_mode = 'w' if first_write else 'a'\n",
    "    \n",
    "    # Write to the DB file\n",
    "    with open(output_db_file, db_mode) as db_file:\n",
    "        filtered_chunk.to_json(db_file, orient='records', lines=True)\n",
    "    \n",
    "    # Write to the streaming file\n",
    "    with open(output_streaming_file, streaming_mode) as streaming_file:\n",
    "        streaming_chunk.to_json(streaming_file, orient='records', lines=True)\n",
    "    \n",
    "    # After first write, switch to append mode\n",
    "    first_write = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_100k_reviews = pd.read_json('db_data/db_reviews.jsonl', lines=True, nrows=100000)\n",
    "# first_100k_reviews.to_json('small_db_data/db_reviews_100k.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2330"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_ratings = pd.read_json('dags/streaming_data/streaming_ratings.jsonl', lines=True)\n",
    "len(streaming_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "4255      1978\n",
       "170777     311\n",
       "152131      16\n",
       "130480      11\n",
       "200400       5\n",
       "180571       3\n",
       "173031       3\n",
       "186729       2\n",
       "167458       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_ratings['item_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_reviews = pd.read_json('dags/streaming_data/streaming_reviews.jsonl', lines=True)\n",
    "len(streaming_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id\n",
       "4255      637\n",
       "130480     20\n",
       "152131     11\n",
       "173031      5\n",
       "170777      4\n",
       "148610      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_reviews['item_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      4255\n",
      "1    170777\n",
      "2    130480\n",
      "3    152131\n",
      "4    180571\n",
      "5    173031\n",
      "6    200400\n",
      "7    186729\n",
      "8    167458\n",
      "9    148610\n",
      "Name: item_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenate and keep only unique item_ids\n",
    "unique_item_ids = pd.concat([streaming_ratings['item_id'], streaming_reviews['item_id']]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Display the resulting unique item_ids\n",
    "print(unique_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
